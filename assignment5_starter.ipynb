{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "17vfaEGlFnGg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nUEj4_mkFnGi"
      },
      "outputs": [],
      "source": [
        "def most_common_label(arr):\n",
        "    length = len(arr)\n",
        "    prob = np.sum(arr == 1) / length\n",
        "    return round(prob, 2), int(prob >= 0.5)\n",
        "\n",
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k, distance_metric):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "      predictions, probabilities = [], []\n",
        "      for x in X:\n",
        "          distances = self.compute_distance(self.X_train, x)\n",
        "          k_nearest_indices = np.argsort(distances)[:self.k]\n",
        "          k_nearest_labels = self.y_train[k_nearest_indices]\n",
        "          prob, common = most_common_label(k_nearest_labels)\n",
        "          predictions.append(common)\n",
        "          probabilities.append(prob)\n",
        "      return predictions, probabilities\n",
        "\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        X1_without_index = X1[:, 1:]  # Remove index column from X1\n",
        "        X2_without_index = X2[1:]  # Remove index from X2\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            distances = np.sqrt(np.sum((X1_without_index - X2_without_index) ** 2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            distances = np.sum(np.abs(X1_without_index - X2_without_index), axis=1)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "        return distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L03qxL8rFnGj"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(train_path, test_path):\n",
        "    # Load data\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Handle missing values by dropping rows with any missing values\n",
        "    train_data = train_data.dropna()\n",
        "    test_data = test_data.dropna()\n",
        "\n",
        "    X = train_data.drop(columns=['CustomerId', 'Surname', 'Exited','Geography', 'Gender'])\n",
        "    y = train_data['Exited'].values\n",
        "    X_test = test_data.drop(columns=['CustomerId', 'Surname','Geography', 'Gender'])\n",
        "\n",
        "    numerical_cols = train_data.select_dtypes(include=[np.number]).columns\n",
        "    X = (X - X.mean()) / X.std()\n",
        "    X_test = (X_test - X_test.mean()) / X_test.std()\n",
        "\n",
        "    X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "    return X.values, y, X_test.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b8G_Bop7FnGj"
      },
      "outputs": [],
      "source": [
        "def cross_validate(X, y, knn, n_splits):\n",
        "    n_samples = len(X)\n",
        "    fold_size = n_samples // n_splits\n",
        "    scores = {'roc_auc': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        start, end = i * fold_size, (i + 1) * fold_size\n",
        "\n",
        "        # val and train sets created\n",
        "        X_val = X[start:end]\n",
        "        y_val = y[start:end]\n",
        "        X_train = np.concatenate([X[:start], X[end:]])\n",
        "        y_train = np.concatenate([y[:start], y[end:]])\n",
        "\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred, probs = knn.predict(X_val)\n",
        "\n",
        "        auc_score, accuracy, precision, recall, f1_score = calculate_metrics(y_val, y_pred)\n",
        "        print(f\"Fold {i + 1}: auc-score:{auc_score}, accuracy:{accuracy}, precision:{precision}, recall:{recall}, f1-score:{f1_score}\")\n",
        "\n",
        "        scores['roc_auc'].append(auc_score)\n",
        "        scores['accuracy'].append(accuracy)\n",
        "        scores['precision'].append(precision)\n",
        "        scores['recall'].append(recall)\n",
        "        scores['f1_score'].append(f1_score)\n",
        "\n",
        "    return {metric: np.mean(scores[metric]) for metric in scores}\n",
        "\n",
        "def calculate_metrics(y_true, y_scores):\n",
        "    # sort the instances by the predicted score in descending order\n",
        "    sorted_indices = np.argsort(y_scores)[::-1]\n",
        "    y_true = y_true[sorted_indices]\n",
        "    y_scores = np.array(y_scores)\n",
        "    y_scores = y_scores[sorted_indices]\n",
        "\n",
        "    # total number of positive and negative samples\n",
        "    P = np.sum(y_true)\n",
        "    N = len(y_true) - P\n",
        "\n",
        "    tp = np.sum((y_true == 1.0) & (y_scores == 1.0))\n",
        "    tn = np.sum((y_true == 0.0) & (y_scores == 0.0))\n",
        "    fp = np.sum((y_true == 0.0) & (y_scores == 1.0))\n",
        "    fn = np.sum((y_true == 1.0) & (y_scores == 0.0))\n",
        "\n",
        "    accuracy = (tp + tn) / len(y_true)\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # true pos rate, false pos rate\n",
        "    tpr, fpr = [], []\n",
        "    tp, fp = 0, 0\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        if y_true[i] == 1:\n",
        "            tp += 1\n",
        "        else:\n",
        "            fp += 1\n",
        "\n",
        "        tpr.append(tp / P if P > 0 else 0)\n",
        "        fpr.append(fp / N if N > 0 else 0)\n",
        "\n",
        "    # Calculate the area under the curve using the trapezoidal rule\n",
        "    auc = 0.0\n",
        "    for i in range(1, len(tpr)):\n",
        "        auc += (fpr[i] - fpr[i - 1]) * (tpr[i] + tpr[i - 1]) / 2\n",
        "\n",
        "    return auc, accuracy, precision, recall, f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5G5kkPQFnGj",
        "outputId": "89b80f3a-5536-4abd-df04-f64c52dc2b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: auc-score:0.7855358777128921, accuracy:0.8453333333333334, precision:0.6124260355029586, recall:0.672077922077922, f1-score:0.6408668730650154\n",
            "Fold 2: auc-score:0.7938791334028867, accuracy:0.8566666666666667, precision:0.6180981595092024, recall:0.690068493150685, f1-score:0.6521035598705502\n",
            "Fold 3: auc-score:0.7814762579004052, accuracy:0.856, precision:0.6299694189602446, recall:0.6843853820598007, f1-score:0.6560509554140128\n",
            "Fold 4: auc-score:0.807074290484139, accuracy:0.864, precision:0.653125, recall:0.6920529801324503, f1-score:0.6720257234726686\n",
            "Fold 5: auc-score:0.7718101905339951, accuracy:0.854, precision:0.6497622820919176, recall:0.6539074960127592, f1-score:0.6518282988871223\n",
            "Cross-validation results (Euclidean): {'roc_auc': 0.7879551500068637, 'accuracy': 0.8552, 'precision': 0.6326761792128647, 'recall': 0.6784984546867234, 'f1_score': 0.6545750821418739}\n",
            "Fold 1: auc-score:0.7762688758389269, accuracy:0.841, precision:0.6023564064801178, recall:0.663961038961039, f1-score:0.6316602316602317\n",
            "Fold 2: auc-score:0.7907734112764236, accuracy:0.8566666666666667, precision:0.6214511041009464, recall:0.6746575342465754, f1-score:0.6469622331691297\n",
            "Fold 3: auc-score:0.7731782299202793, accuracy:0.856, precision:0.6353503184713376, recall:0.6627906976744186, f1-score:0.6487804878048781\n",
            "Fold 4: auc-score:0.8004870147818145, accuracy:0.8606666666666667, precision:0.6448598130841121, recall:0.6854304635761589, f1-score:0.6645264847512038\n",
            "Fold 5: auc-score:0.770400794154869, accuracy:0.8533333333333334, precision:0.6477093206951027, recall:0.6539074960127592, f1-score:0.6507936507936508\n",
            "Cross-validation results (Manhattan): {'roc_auc': 0.7822216651944627, 'accuracy': 0.8535333333333334, 'precision': 0.6303453925663234, 'recall': 0.6681494460941902, 'f1_score': 0.6485446176358187}\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# KNN with Euclidean distance\n",
        "knn_euclidean = KNN(k=4, distance_metric='euclidean')\n",
        "cv_scores_euclidean = cross_validate(X, y, knn_euclidean, n_splits=5)\n",
        "print(\"Cross-validation results (Euclidean):\", cv_scores_euclidean)\n",
        "\n",
        "# KNN with Manhattan distance\n",
        "knn_manhattan = KNN(k=4, distance_metric='manhattan')\n",
        "cv_scores_manhattan = cross_validate(X, y, knn_manhattan, n_splits=5)\n",
        "print(\"Cross-validation results (Manhattan):\", cv_scores_manhattan)\n",
        "\n",
        "best_k = 4\n",
        "knn_best = KNN(k=best_k, distance_metric='euclidean')\n",
        "\n",
        "# Train on the full dataset with optimal hyperparameters and make predictions on the test set\n",
        "knn_best.fit(X, y)\n",
        "test_predictions, probabilities = knn_best.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': probabilities}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}